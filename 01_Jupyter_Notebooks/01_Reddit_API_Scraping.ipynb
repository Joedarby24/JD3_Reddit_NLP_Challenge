{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/Y6EMKKg.jpg\" style=\"float: left; margin: 15px;\" width=\"75\">\n",
    "\n",
    "# Import Python Libraries Needed\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import sys, json\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Reddit URL's for Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_t = 'https://www.reddit.com/r/The_Donald.json'\n",
    "\n",
    "url_r = 'https://www.reddit.com/r/esist.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Received 429 error for the following code:**\n",
    "\n",
    "``res_t = requests.get(url_t)\n",
    "res_r = requests.get(url_r)\n",
    "res_t.status_code\n",
    "res_r.status_code``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a user agent to get around the '429: \"too many requests\" error\n",
    "headers = {'User-agent' : 'Jojo_Gun' }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_t = requests.get(url_t, headers=headers)\n",
    "res_r = requests.get(url_r, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm that each sub-reddit does not return error code\n",
    "print(res_t.status_code)\n",
    "res_t.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the Reddit API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_t = res_t.json()\n",
    "json_r = res_r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['kind', 'data'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['kind', 'data'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirmed same key structure \n",
    "print(json_t.keys())\n",
    "json_r.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listing\n",
      "Listing\n"
     ]
    }
   ],
   "source": [
    "print(json_t['kind'])\n",
    "print(json_r['kind'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There is one data type for this key, so we can assume that everything we want will be in the outher key, 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['modhash', 'dist', 'children', 'after', 'before'])\n",
      "dict_keys(['modhash', 'dist', 'children', 'after', 'before'])\n",
      "['after', 'before', 'children', 'dist', 'modhash']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['after', 'before', 'children', 'dist', 'modhash']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirmed that all of the data is indeed in the other key. \n",
    "print(json_t['data'].keys())\n",
    "print(json_r['data'].keys())\n",
    "print(sorted(json_t['data']))\n",
    "sorted(json_r['data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The 'children' key is where we will find our posts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'approved_at_utc': None,\n",
       " 'subreddit': 'esist',\n",
       " 'selftext': '',\n",
       " 'author_fullname': 't2_884o7',\n",
       " 'saved': False,\n",
       " 'mod_reason_title': None,\n",
       " 'gilded': 0,\n",
       " 'clicked': False,\n",
       " 'title': 'House panel votes to authorize subpoena for unredacted Mueller report',\n",
       " 'link_flair_richtext': [],\n",
       " 'subreddit_name_prefixed': 'r/esist',\n",
       " 'hidden': False,\n",
       " 'pwls': 1,\n",
       " 'link_flair_css_class': None,\n",
       " 'downs': 0,\n",
       " 'thumbnail_height': 73,\n",
       " 'hide_score': False,\n",
       " 'name': 't3_b95ss5',\n",
       " 'quarantine': False,\n",
       " 'link_flair_text_color': 'dark',\n",
       " 'author_flair_background_color': None,\n",
       " 'subreddit_type': 'public',\n",
       " 'ups': 14,\n",
       " 'domain': 'cnbc.com',\n",
       " 'media_embed': {},\n",
       " 'thumbnail_width': 140,\n",
       " 'author_flair_template_id': None,\n",
       " 'is_original_content': False,\n",
       " 'user_reports': [],\n",
       " 'secure_media': None,\n",
       " 'is_reddit_media_domain': False,\n",
       " 'is_meta': False,\n",
       " 'category': None,\n",
       " 'secure_media_embed': {},\n",
       " 'link_flair_text': None,\n",
       " 'can_mod_post': False,\n",
       " 'score': 14,\n",
       " 'approved_by': None,\n",
       " 'thumbnail': 'https://b.thumbs.redditmedia.com/rQQPRP7_BHb_Q3QrIepE3V905eNQjV8eDp0u0geuj4o.jpg',\n",
       " 'edited': False,\n",
       " 'author_flair_css_class': None,\n",
       " 'author_flair_richtext': [],\n",
       " 'gildings': {'gid_1': 0, 'gid_2': 0, 'gid_3': 0},\n",
       " 'post_hint': 'link',\n",
       " 'content_categories': None,\n",
       " 'is_self': False,\n",
       " 'mod_note': None,\n",
       " 'created': 1554336884.0,\n",
       " 'link_flair_type': 'text',\n",
       " 'wls': 1,\n",
       " 'banned_by': None,\n",
       " 'author_flair_type': 'text',\n",
       " 'contest_mode': False,\n",
       " 'selftext_html': None,\n",
       " 'likes': None,\n",
       " 'suggested_sort': 'confidence',\n",
       " 'banned_at_utc': None,\n",
       " 'view_count': None,\n",
       " 'archived': False,\n",
       " 'no_follow': False,\n",
       " 'is_crosspostable': False,\n",
       " 'pinned': False,\n",
       " 'over_18': False,\n",
       " 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/5iKpTDH3L52DWNnK_EXLI9dbCeOlk4UbA8jv9IGssIY.jpg?auto=webp&amp;s=5156c651e8921bd0f5dd3c16e87c05983cd25c80',\n",
       "     'width': 1910,\n",
       "     'height': 1000},\n",
       "    'resolutions': [{'url': 'https://external-preview.redd.it/5iKpTDH3L52DWNnK_EXLI9dbCeOlk4UbA8jv9IGssIY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=246563aecf1710061133d10b6d393407156d47ae',\n",
       "      'width': 108,\n",
       "      'height': 56},\n",
       "     {'url': 'https://external-preview.redd.it/5iKpTDH3L52DWNnK_EXLI9dbCeOlk4UbA8jv9IGssIY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=85131fd2827a64e4df90afc138aebe38a1631798',\n",
       "      'width': 216,\n",
       "      'height': 113},\n",
       "     {'url': 'https://external-preview.redd.it/5iKpTDH3L52DWNnK_EXLI9dbCeOlk4UbA8jv9IGssIY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=63fe278a7f1d065ff47c7afe678ade4924bd448d',\n",
       "      'width': 320,\n",
       "      'height': 167},\n",
       "     {'url': 'https://external-preview.redd.it/5iKpTDH3L52DWNnK_EXLI9dbCeOlk4UbA8jv9IGssIY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=0675f8223654230b36b34ea83453667c1166760a',\n",
       "      'width': 640,\n",
       "      'height': 335},\n",
       "     {'url': 'https://external-preview.redd.it/5iKpTDH3L52DWNnK_EXLI9dbCeOlk4UbA8jv9IGssIY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=3f06cdef2b7331ea5e2d1f9609d37d13cd052c5a',\n",
       "      'width': 960,\n",
       "      'height': 502},\n",
       "     {'url': 'https://external-preview.redd.it/5iKpTDH3L52DWNnK_EXLI9dbCeOlk4UbA8jv9IGssIY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=dd578f819ce6ff9596d74bbe932c455107eceef1',\n",
       "      'width': 1080,\n",
       "      'height': 565}],\n",
       "    'variants': {},\n",
       "    'id': 'kjHz7MG6XVDGH3SknQSy2257Ecf-ZZVUISqjyasHUdg'}],\n",
       "  'enabled': False},\n",
       " 'media_only': False,\n",
       " 'can_gild': False,\n",
       " 'spoiler': False,\n",
       " 'locked': False,\n",
       " 'author_flair_text': None,\n",
       " 'visited': False,\n",
       " 'num_reports': None,\n",
       " 'distinguished': None,\n",
       " 'subreddit_id': 't5_3irqb',\n",
       " 'mod_reason_by': None,\n",
       " 'removal_reason': None,\n",
       " 'link_flair_background_color': '',\n",
       " 'id': 'b95ss5',\n",
       " 'is_robot_indexable': True,\n",
       " 'report_reasons': None,\n",
       " 'author': 'MichaelTen',\n",
       " 'num_crossposts': 0,\n",
       " 'num_comments': 1,\n",
       " 'send_replies': False,\n",
       " 'whitelist_status': 'house_only',\n",
       " 'mod_reports': [],\n",
       " 'author_patreon_flair': False,\n",
       " 'author_flair_text_color': None,\n",
       " 'permalink': '/r/esist/comments/b95ss5/house_panel_votes_to_authorize_subpoena_for/',\n",
       " 'parent_whitelist_status': 'house_only',\n",
       " 'stickied': False,\n",
       " 'url': 'https://www.cnbc.com/2019/04/03/house-panel-set-to-vote-on-subpoenas-for-unredacted-mueller-report-and-former-trump-associates.html',\n",
       " 'subreddit_subscribers': 125135,\n",
       " 'created_utc': 1554336884.0,\n",
       " 'media': None,\n",
       " 'is_video': False}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the structure of the last post per subreddit\n",
    "json_t['data']['children'][25]\n",
    "json_r['data']['children'][26]['data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I noticed that there are 26 posts returned by The_Donald and 27 by esist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "print(len(json_t['data']['children']))  # 27 posts per page\n",
    "print(len(json_r['data']['children']))  # 26 posts per page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'approved_at_utc': None,\n",
       " 'subreddit': 'esist',\n",
       " 'selftext': '[Click here to go to the more detailed wiki](https://www.reddit.com/r/esist/wiki/index)\\n\\n[Follow us on Twitter!](https://twitter.com/redditresist)\\n\\nPlease message the moderators or comment on this thread if you have new links, especially to local resistance groups.\\n\\n* A Practical Guide for Resisting the Trump Agenda: https://www.indivisibleguide.com/\\n\\n* Claire McCaskill: Any federal employee who wants to visit, we will listen. We will protect you. whistleblowers@mccaskill.senate.gov\\n202-224-2630\\n\\n* Make 5 calls a day to Congressmen in five minutes: https://5calls.org/\\n\\n* Sign up for daily text alerts for direct action: https://dailyaction.org/\\n\\n* This script is for complaining about the selling of public lands, but could be tweaked to be useful elsewhere. https://docs.google.com/document/d/10cmFKG3t30XAGQEHNyaVf3DZpx2cJOClgmKdJHCuIuA/edit\\n\\n* Here is information on voicing your opposition to the nomination of Pruitt to EPA: http://www.nrdcactionfund.org/call-your-senators-and-ask-them-to-oppose-scott-pruitts-confirmation/\\n\\n* To find out offices that you can run for, visit https://www.runforoffice.org/\\n\\n* Run for something: https://www.runforsomething.net/\\n\\n* Script specific to Senators who already oppose the Muslim ban to get them to do more. https://www.indivisibleguide.com/resources-2/2017/1/30/your-senator-opposes-the-muslim-ban-so-tell-them-how-to-stop-it\\n\\n* Camp Wellstone, a training camp for progressive candidates: http://www.wellstone.org/\\n\\n* LibrariesResist Resource List: https://docs.google.com/document/d/1g79sSAlP03rdiVHraeb9PFlhbL_5ZLVFFRYiOqhZs_w/pub\\n\\n* Weekly acts of resistance: https://www.wall-of-us.org/weekly-acts-of-resistance/\\n\\n* \"Our mission is to turn America blue by building a movement to flip seats.\": https://www.flippable.org/ \\n\\n* The 99 ways to fight trump: https://99waystofighttrump.com',\n",
       " 'author_fullname': 't2_14s7o3',\n",
       " 'saved': False,\n",
       " 'mod_reason_title': None,\n",
       " 'gilded': 1,\n",
       " 'clicked': False,\n",
       " 'title': 'Thread for Useful Links',\n",
       " 'link_flair_richtext': [],\n",
       " 'subreddit_name_prefixed': 'r/esist',\n",
       " 'hidden': False,\n",
       " 'pwls': 1,\n",
       " 'link_flair_css_class': None,\n",
       " 'downs': 0,\n",
       " 'thumbnail_height': None,\n",
       " 'hide_score': False,\n",
       " 'name': 't3_5rid3d',\n",
       " 'quarantine': False,\n",
       " 'link_flair_text_color': 'dark',\n",
       " 'author_flair_background_color': None,\n",
       " 'subreddit_type': 'public',\n",
       " 'ups': 968,\n",
       " 'domain': 'self.esist',\n",
       " 'media_embed': {},\n",
       " 'thumbnail_width': None,\n",
       " 'author_flair_template_id': None,\n",
       " 'is_original_content': False,\n",
       " 'user_reports': [],\n",
       " 'secure_media': None,\n",
       " 'is_reddit_media_domain': False,\n",
       " 'is_meta': False,\n",
       " 'category': None,\n",
       " 'secure_media_embed': {},\n",
       " 'link_flair_text': None,\n",
       " 'can_mod_post': False,\n",
       " 'score': 968,\n",
       " 'approved_by': None,\n",
       " 'thumbnail': 'self',\n",
       " 'edited': 1487892303.0,\n",
       " 'author_flair_css_class': None,\n",
       " 'author_flair_richtext': [],\n",
       " 'gildings': {'gid_1': 0, 'gid_2': 1, 'gid_3': 0},\n",
       " 'post_hint': 'self',\n",
       " 'content_categories': None,\n",
       " 'is_self': True,\n",
       " 'mod_note': None,\n",
       " 'created': 1485984493.0,\n",
       " 'link_flair_type': 'text',\n",
       " 'wls': 1,\n",
       " 'banned_by': None,\n",
       " 'author_flair_type': 'text',\n",
       " 'contest_mode': False,\n",
       " 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.reddit.com/r/esist/wiki/index\"&gt;Click here to go to the more detailed wiki&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\"https://twitter.com/redditresist\"&gt;Follow us on Twitter!&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Please message the moderators or comment on this thread if you have new links, especially to local resistance groups.&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;&lt;p&gt;A Practical Guide for Resisting the Trump Agenda: &lt;a href=\"https://www.indivisibleguide.com/\"&gt;https://www.indivisibleguide.com/&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;\\n&lt;li&gt;&lt;p&gt;Claire McCaskill: Any federal employee who wants to visit, we will listen. We will protect you. &lt;a href=\"mailto:whistleblowers@mccaskill.senate.gov\"&gt;whistleblowers@mccaskill.senate.gov&lt;/a&gt;\\n202-224-2630&lt;/p&gt;&lt;/li&gt;\\n&lt;li&gt;&lt;p&gt;Make 5 calls a day to Congressmen in five minutes: &lt;a href=\"https://5calls.org/\"&gt;https://5calls.org/&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;\\n&lt;li&gt;&lt;p&gt;Sign up for daily text alerts for direct action: &lt;a href=\"https://dailyaction.org/\"&gt;https://dailyaction.org/&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;\\n&lt;li&gt;&lt;p&gt;This script is for complaining about the selling of public lands, but could be tweaked to be useful elsewhere. &lt;a href=\"https://docs.google.com/document/d/10cmFKG3t30XAGQEHNyaVf3DZpx2cJOClgmKdJHCuIuA/edit\"&gt;https://docs.google.com/document/d/10cmFKG3t30XAGQEHNyaVf3DZpx2cJOClgmKdJHCuIuA/edit&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;\\n&lt;li&gt;&lt;p&gt;Here is information on voicing your opposition to the nomination of Pruitt to EPA: &lt;a href=\"http://www.nrdcactionfund.org/call-your-senators-and-ask-them-to-oppose-scott-pruitts-confirmation/\"&gt;http://www.nrdcactionfund.org/call-your-senators-and-ask-them-to-oppose-scott-pruitts-confirmation/&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;\\n&lt;li&gt;&lt;p&gt;To find out offices that you can run for, visit &lt;a href=\"https://www.runforoffice.org/\"&gt;https://www.runforoffice.org/&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;\\n&lt;li&gt;&lt;p&gt;Run for something: &lt;a href=\"https://www.runforsomething.net/\"&gt;https://www.runforsomething.net/&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;\\n&lt;li&gt;&lt;p&gt;Script specific to Senators who already oppose the Muslim ban to get them to do more. &lt;a href=\"https://www.indivisibleguide.com/resources-2/2017/1/30/your-senator-opposes-the-muslim-ban-so-tell-them-how-to-stop-it\"&gt;https://www.indivisibleguide.com/resources-2/2017/1/30/your-senator-opposes-the-muslim-ban-so-tell-them-how-to-stop-it&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;\\n&lt;li&gt;&lt;p&gt;Camp Wellstone, a training camp for progressive candidates: &lt;a href=\"http://www.wellstone.org/\"&gt;http://www.wellstone.org/&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;\\n&lt;li&gt;&lt;p&gt;LibrariesResist Resource List: &lt;a href=\"https://docs.google.com/document/d/1g79sSAlP03rdiVHraeb9PFlhbL_5ZLVFFRYiOqhZs_w/pub\"&gt;https://docs.google.com/document/d/1g79sSAlP03rdiVHraeb9PFlhbL_5ZLVFFRYiOqhZs_w/pub&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;\\n&lt;li&gt;&lt;p&gt;Weekly acts of resistance: &lt;a href=\"https://www.wall-of-us.org/weekly-acts-of-resistance/\"&gt;https://www.wall-of-us.org/weekly-acts-of-resistance/&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;\\n&lt;li&gt;&lt;p&gt;&amp;quot;Our mission is to turn America blue by building a movement to flip seats.&amp;quot;: &lt;a href=\"https://www.flippable.org/\"&gt;https://www.flippable.org/&lt;/a&gt; &lt;/p&gt;&lt;/li&gt;\\n&lt;li&gt;&lt;p&gt;The 99 ways to fight trump: &lt;a href=\"https://99waystofighttrump.com\"&gt;https://99waystofighttrump.com&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;\\n&lt;/ul&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;',\n",
       " 'likes': None,\n",
       " 'suggested_sort': 'confidence',\n",
       " 'banned_at_utc': None,\n",
       " 'view_count': None,\n",
       " 'archived': True,\n",
       " 'no_follow': False,\n",
       " 'is_crosspostable': False,\n",
       " 'pinned': False,\n",
       " 'over_18': False,\n",
       " 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/N22WEk-o78FAMOBHVzkuO61XH-V3k8XvCL3TWrOb1LA.jpg?auto=webp&amp;s=8584f67389a5a385124c719a13de7535af1b87dc',\n",
       "     'width': 1000,\n",
       "     'height': 1294},\n",
       "    'resolutions': [{'url': 'https://external-preview.redd.it/N22WEk-o78FAMOBHVzkuO61XH-V3k8XvCL3TWrOb1LA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ac97879fe55149139ae13c6167a7049a731446ac',\n",
       "      'width': 108,\n",
       "      'height': 139},\n",
       "     {'url': 'https://external-preview.redd.it/N22WEk-o78FAMOBHVzkuO61XH-V3k8XvCL3TWrOb1LA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c24af29afddc166b3c7fb14d6388908dc5a74cdb',\n",
       "      'width': 216,\n",
       "      'height': 279},\n",
       "     {'url': 'https://external-preview.redd.it/N22WEk-o78FAMOBHVzkuO61XH-V3k8XvCL3TWrOb1LA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e1899589b87c07a4ebd0188615b238b6b30f32c7',\n",
       "      'width': 320,\n",
       "      'height': 414},\n",
       "     {'url': 'https://external-preview.redd.it/N22WEk-o78FAMOBHVzkuO61XH-V3k8XvCL3TWrOb1LA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=785a0c3e5e77e5cafd5ee525d2ca9b1fd3baa831',\n",
       "      'width': 640,\n",
       "      'height': 828},\n",
       "     {'url': 'https://external-preview.redd.it/N22WEk-o78FAMOBHVzkuO61XH-V3k8XvCL3TWrOb1LA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=6a28d04dbc53c42ec0134f91b631eb71a3a2c322',\n",
       "      'width': 960,\n",
       "      'height': 1242}],\n",
       "    'variants': {},\n",
       "    'id': '3qH1-DdhwCR3cy2S442hS9Vs-qlIga1EeuGFoKOHVYk'}],\n",
       "  'enabled': False},\n",
       " 'media_only': False,\n",
       " 'can_gild': False,\n",
       " 'spoiler': False,\n",
       " 'locked': False,\n",
       " 'author_flair_text': None,\n",
       " 'visited': False,\n",
       " 'num_reports': None,\n",
       " 'distinguished': 'moderator',\n",
       " 'subreddit_id': 't5_3irqb',\n",
       " 'mod_reason_by': None,\n",
       " 'removal_reason': None,\n",
       " 'link_flair_background_color': '',\n",
       " 'id': '5rid3d',\n",
       " 'is_robot_indexable': True,\n",
       " 'report_reasons': None,\n",
       " 'author': 'resistmod',\n",
       " 'num_crossposts': 0,\n",
       " 'num_comments': 113,\n",
       " 'send_replies': True,\n",
       " 'whitelist_status': 'house_only',\n",
       " 'mod_reports': [],\n",
       " 'author_patreon_flair': False,\n",
       " 'author_flair_text_color': None,\n",
       " 'permalink': '/r/esist/comments/5rid3d/thread_for_useful_links/',\n",
       " 'parent_whitelist_status': 'house_only',\n",
       " 'stickied': True,\n",
       " 'url': 'https://www.reddit.com/r/esist/comments/5rid3d/thread_for_useful_links/',\n",
       " 'subreddit_subscribers': 125135,\n",
       " 'created_utc': 1485984493.0,\n",
       " 'media': None,\n",
       " 'is_video': False}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is showing the data of the first post of the subreddits\n",
    "json_t['data']['children'][0]['data']\n",
    "# and/or\n",
    "json_r['data']['children'][0]['data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Pandas DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In essence, we have a dataframe\n",
    "df_t = pd.DataFrame(json_t['data']['children'])\n",
    "df_r = pd.DataFrame(json_r['data']['children'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>kind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'approved_at_utc': None, 'subreddit': 'The_Do...</td>\n",
       "      <td>t3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'approved_at_utc': None, 'subreddit': 'The_Do...</td>\n",
       "      <td>t3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'approved_at_utc': None, 'subreddit': 'The_Do...</td>\n",
       "      <td>t3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'approved_at_utc': None, 'subreddit': 'The_Do...</td>\n",
       "      <td>t3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'approved_at_utc': None, 'subreddit': 'The_Do...</td>\n",
       "      <td>t3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data kind\n",
       "0  {'approved_at_utc': None, 'subreddit': 'The_Do...   t3\n",
       "1  {'approved_at_utc': None, 'subreddit': 'The_Do...   t3\n",
       "2  {'approved_at_utc': None, 'subreddit': 'The_Do...   t3\n",
       "3  {'approved_at_utc': None, 'subreddit': 'The_Do...   t3\n",
       "4  {'approved_at_utc': None, 'subreddit': 'The_Do...   t3"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The_Donald\n",
    "df_t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>kind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'approved_at_utc': None, 'subreddit': 'esist'...</td>\n",
       "      <td>t3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'approved_at_utc': None, 'subreddit': 'esist'...</td>\n",
       "      <td>t3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'approved_at_utc': None, 'subreddit': 'esist'...</td>\n",
       "      <td>t3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'approved_at_utc': None, 'subreddit': 'esist'...</td>\n",
       "      <td>t3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'approved_at_utc': None, 'subreddit': 'esist'...</td>\n",
       "      <td>t3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data kind\n",
       "0  {'approved_at_utc': None, 'subreddit': 'esist'...   t3\n",
       "1  {'approved_at_utc': None, 'subreddit': 'esist'...   t3\n",
       "2  {'approved_at_utc': None, 'subreddit': 'esist'...   t3\n",
       "3  {'approved_at_utc': None, 'subreddit': 'esist'...   t3\n",
       "4  {'approved_at_utc': None, 'subreddit': 'esist'...   t3"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# esist\n",
    "df_r.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting Multiple Pages of Data from the Reddit API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t3_b95ss5'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_t['data']['after']\n",
    "# and/or\n",
    "json_r['data']['after']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The 'after' key returns the ID of the post. This particular statement returns the last ID from our list of 25 posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_id = [post['data']['name'] for post in json_t['data']['children']]  \n",
    "len(t_id)\n",
    "\n",
    "r_id = [post['data']['name'] for post in json_r['data']['children']]  \n",
    "len(r_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As post = integer indecies, this type of iteration works. These ID's will need to be you ANCHORS for the next time your Python script hits the Reddit API for reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to hit the next 25 posts, we need to specify the ID where we left off when we make our next request.\n",
    "We do this through the param argument of requests.get and pass through a dictionary specifiying the location:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The_Donald\n",
    "param_t = {'after': 't3_b7n1tt'}\n",
    "res = requests.get(url, params=param_t, headers=headers)\n",
    "res.status_code\n",
    "\n",
    "# esist: \n",
    "param_r = {'after': 't3_b7324u'}\n",
    "res_r = requests.get(url_r, params=param_r, headers=headers)\n",
    "res.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can set up a for loop to to hit the API a given number of times (specified through a range):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 t3_b9c4of\n",
      "1 t3_b9b4s8\n",
      "2 t3_b9iydh\n",
      "3 t3_b9b9mk\n",
      "4 t3_b9j6rv\n",
      "5 t3_b9hrxf\n",
      "6 t3_b9kfth\n",
      "7 t3_b9b64p\n",
      "8 t3_b9gwdp\n",
      "9 t3_b9jr6v\n",
      "10 t3_b9jbqx\n",
      "11 t3_b9k79w\n",
      "12 t3_b9h7oc\n",
      "13 t3_b9gmwv\n",
      "14 t3_b94xn8\n",
      "15 t3_b9fikc\n",
      "16 t3_b9khd8\n",
      "17 t3_b9if39\n",
      "18 t3_b9l09d\n",
      "19 t3_b9jeuw\n",
      "20 t3_b9jz7s\n",
      "21 t3_b9keqh\n",
      "22 t3_b9b54b\n",
      "23 t3_b9kipp\n",
      "24 t3_b9jyjb\n",
      "25 t3_b9kkyu\n",
      "26 t3_b9k1xd\n",
      "27 t3_b9gsi4\n",
      "28 t3_b9heks\n",
      "29 t3_b9bjcq\n",
      "30 t3_b9d5be\n",
      "31 t3_b9fu62\n",
      "32 t3_b9j5ka\n",
      "33 t3_b9j3tq\n",
      "34 t3_b9d9bq\n",
      "35 t3_b9f2mv\n",
      "36 t3_b93zpi\n",
      "37 t3_b9hxs5\n",
      "38 t3_b9by3m\n"
     ]
    }
   ],
   "source": [
    "posts_t = []\n",
    "after_t = None\n",
    "\n",
    "for i in range(39):  # for loop will run through 216 iterations\n",
    "    if after_t == None:      # to start us off with an empty parameter dictionary\n",
    "        param_t = {}        # the empty prameter dictionary\n",
    "    else:                  # this will run after the first iteration as after = the next post id at the end of the for loop\n",
    "        param_t = {'after': after_t}               # the new parameter dictionary specified with the next post id\n",
    "    url_t = 'https://www.reddit.com/r/The_Donald.json'                   # URL to hit\n",
    "    res_t = requests.get(url_t, params=param_t, headers=headers)    # request the json content from URL with the following params\n",
    "    if res_t.status_code == 200:                                    # if our request was accepted, run the next code\n",
    "        json_t = res_t.json()                                       # point the requested json content to the_json variable\n",
    "        posts_t.extend(json_t['data']['children'])    # List method: .extend() to add the json content to the body of the list. .append() adds another dict to the list\n",
    "        after_t = json_t['data']['after']     # after is redefined to the name of the next post id until the loops is done\n",
    "        print(i, after_t)                     # print the number of iterartions\n",
    "    else:                                     # else: if we get a status code other than 200\n",
    "        print(res_t.status_code)                # print the status code\n",
    "        break                                 # then break the loop\n",
    "    time.sleep(2)                             # wait two seconds to run the next iteration of the for loop\n",
    "    \n",
    "    \n",
    "    \n",
    "df_tpost = pd.DataFrame(posts_t)\n",
    "\n",
    "df_tpost.to_csv('./data/The_Donald_Scrape.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(977, 2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tpost.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can set up a for loop to to hit the API a given number of times (specified through a range):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 t3_b95ss5\n",
      "1 t3_b8ixq4\n",
      "2 t3_b7yln6\n",
      "3 t3_b6xf53\n",
      "4 t3_b6ifmk\n",
      "5 t3_b5sssh\n",
      "6 t3_b5h8zx\n",
      "7 t3_b59nxp\n",
      "8 t3_b4odtd\n",
      "9 t3_b3ytzk\n",
      "10 t3_b3c2dn\n",
      "11 t3_b2k31r\n",
      "12 t3_b261ty\n",
      "13 t3_b1t047\n",
      "14 t3_b0v5wz\n",
      "15 t3_b16cq2\n",
      "16 t3_b09718\n",
      "17 t3_b0ai4f\n",
      "18 t3_azkr5s\n",
      "19 t3_azt6ti\n",
      "20 t3_ayx25g\n",
      "21 t3_ayvm5j\n",
      "22 t3_ay6drn\n",
      "23 t3_axzblm\n",
      "24 t3_axlulm\n",
      "25 t3_axay3y\n",
      "26 t3_awxchp\n",
      "27 t3_awc697\n",
      "28 t3_aw4eko\n",
      "29 None\n"
     ]
    }
   ],
   "source": [
    "posts_r = []\n",
    "after_r = None\n",
    "\n",
    "for i in range(30):\n",
    "    if after_r == None:\n",
    "        param_r = {}\n",
    "    else:                  \n",
    "        param_r = {'after': after_r}               \n",
    "    url_r = 'https://www.reddit.com/r/esist.json'                   \n",
    "    res_r = requests.get(url_r, params=param_r, headers=headers)    \n",
    "    if res_r.status_code== 200:       \n",
    "        json_r = res_r.json()       \n",
    "        posts_r.extend(json_r['data']['children'])    \n",
    "        after_r = json_r['data']['after']\n",
    "        print(i, after_r)\n",
    "    else:                                     \n",
    "        print(res_r.status_code)                \n",
    "        break                                 \n",
    "    time.sleep(2) \n",
    "    \n",
    "df_rpost = pd.DataFrame(posts_r)\n",
    "    \n",
    "df_rpost.to_csv('./data/Resist_Scrape.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(744, 2)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rpost.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Combined DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# esist:\n",
    "r_post_titles = [each['data']['title'] for each in posts_r]\n",
    "r_post_url = [each['data']['url'] for each in posts_r]\n",
    "r_post_subreddit = [each['data']['subreddit'] for each in posts_r]\n",
    "\n",
    "\n",
    "# The_Donald\n",
    "t_post_titles = [each['data']['title'] for each in posts_t]\n",
    "t_post_url = [each['data']['url'] for each in posts_t]\n",
    "t_post_subreddit = [each['data']['subreddit'] for each in posts_t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_post_titles = r_post_titles + t_post_titles\n",
    "all_post_url = r_post_url + t_post_url\n",
    "all_post_subreddit = r_post_subreddit + t_post_subreddit\n",
    "p3_dataset = {'post_title': all_post_titles, 'subreddit_name': all_post_subreddit, 'url':all_post_url}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df_shuffled = pd.DataFrame(p3_dataset, columns=[\"post_title\"])\n",
    "df_shuffled = pd.DataFrame(p3_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_title</th>\n",
       "      <th>subreddit_name</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thread for Useful Links</td>\n",
       "      <td>esist</td>\n",
       "      <td>https://www.reddit.com/r/esist/comments/5rid3d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Some on Mueller’s Team See Their Findings as M...</td>\n",
       "      <td>esist</td>\n",
       "      <td>https://www.nytimes.com/2019/04/03/us/politics...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Elizabeth Warren Wants to Make It Easier to Th...</td>\n",
       "      <td>esist</td>\n",
       "      <td>https://www.vanityfair.com/news/2019/04/elizab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Congress: “We’re going to need a copy of the P...</td>\n",
       "      <td>esist</td>\n",
       "      <td>https://www.reddit.com/r/esist/comments/b99z1q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mueller’s Team Gathered ‘Alarming’ Trump Obstr...</td>\n",
       "      <td>esist</td>\n",
       "      <td>https://www.thedailybeast.com/muellers-team-ga...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          post_title subreddit_name  \\\n",
       "0                            Thread for Useful Links          esist   \n",
       "1  Some on Mueller’s Team See Their Findings as M...          esist   \n",
       "2  Elizabeth Warren Wants to Make It Easier to Th...          esist   \n",
       "3  Congress: “We’re going to need a copy of the P...          esist   \n",
       "4  Mueller’s Team Gathered ‘Alarming’ Trump Obstr...          esist   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.reddit.com/r/esist/comments/5rid3d...  \n",
       "1  https://www.nytimes.com/2019/04/03/us/politics...  \n",
       "2  https://www.vanityfair.com/news/2019/04/elizab...  \n",
       "3  https://www.reddit.com/r/esist/comments/b99z1q...  \n",
       "4  https://www.thedailybeast.com/muellers-team-ga...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_shuffled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shuffled.to_csv('./data/Final_Dataset3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Just for Reference:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how I figured out that my original code was looping back over the same tags and populating tons of duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in df_shuffled['data']:\n",
    "    if i['name'] == 't3_b7o4et':\n",
    "        print(True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
